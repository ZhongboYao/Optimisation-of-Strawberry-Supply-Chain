{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acb0a57b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bdc498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Plots.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b188604",
   "metadata": {},
   "source": [
    "## Read_Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019632d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Read_data:\n",
    "  def __init__(self, loc: str, name: str, true_weeks=12, mul=1, time_interval=4, window=10, predict_length=4):\n",
    "    '''\n",
    "    Read and pre-process the data.\n",
    "    The pre-process includes the process of nan-values, rescaling, normalisation, reservation of true weeks, and scanning into windws using the sliding window.\n",
    "\n",
    "    loc: The position of the target file.\n",
    "    name: The name of the data to be addressed as in the following sets.\n",
    "    true_weeks: The number of weeks from which the data is kept as truth for comparison.\n",
    "    mul: Rescale the data according to the index.\n",
    "    time_interval: The number of weeks between the last known week and the first predicted week.\n",
    "    window: The length of the sliding window.\n",
    "    prediction_length: The length of weeks to be predicted.\n",
    "    '''\n",
    "    doc = pd.read_csv(loc)\n",
    "    self.name = name\n",
    "    self.mul = mul\n",
    "    self.window = window\n",
    "    self.predict_length = predict_length\n",
    "    self.scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1)) # Normalisation.\n",
    "    \n",
    "    self.data_all = doc.to_numpy()[:, 1] # All the original data before any pre-process.\n",
    "    self.data_normalised = None\n",
    "\n",
    "    self.window_interval = time_interval + predict_length - 1 # The interval between the window and the predicted week.       \n",
    "                                                              # As many as 'predict_length' weeks are reserved for the later predictions in the same month.                           \n",
    "    self.history_t = None\n",
    "    self.future_t = None\n",
    "    \n",
    "    self._fill()\n",
    "    self._formation()\n",
    "    self.data = self.data_all[:-true_weeks]\n",
    "    self.true_data = self.data_all[-true_weeks:]\n",
    "    self._normalise()\n",
    "    self._scan()\n",
    "    \n",
    "  def _fill(self):\n",
    "    '''\n",
    "    Fill the nan values using the mean of the nearest left-hand and right-hand non-nan values. \n",
    "    The self.data will be replaced by the data filled after calling this function.\n",
    "    '''\n",
    "    data_filled = self.data_all\n",
    "\n",
    "    for index in range(data_filled.shape[0]):\n",
    "      if data_filled[index] == '.':\n",
    "        for i in reversed(range(0, index)):\n",
    "          if data_filled[i] != '.':\n",
    "            left = data_filled[i] # Search for the nearest left hand non-nan value.\n",
    "            break\n",
    "        for i in range(index, data_filled.shape[0]):\n",
    "          if data_filled[i] != '.':\n",
    "            right = data_filled[i]\n",
    "            break\n",
    "        data_filled[index] = str((float(left) + float(right)) / 2)\n",
    "    data_filled[:] = data_filled[:].astype('float64')\n",
    "    \n",
    "    self.data_all = data_filled\n",
    "    \n",
    "  def _formation(self):\n",
    "    '''\n",
    "    Rescaling the data using the multiplier according to the units.\n",
    "    '''\n",
    "    data_format = self.data_all * self.mul\n",
    "    self.data_all = data_format\n",
    "\n",
    "  def _normalise(self):\n",
    "    '''\n",
    "    Normalise the data. \n",
    "    self.data_normalised is used to store the normalised data.\n",
    "    '''\n",
    "    data_scaled = self.scaler.fit_transform(self.data.reshape(-1, 1))\n",
    "    self.data_normalised = data_scaled\n",
    "\n",
    "  def _scan(self):\n",
    "    '''\n",
    "    Using sliding window to scan the data into piecies fed to the LSTM, and the sliding stride is set to 1.\n",
    "    Scan uses the normalised data to generate windows.\n",
    "    tensor history = num of windows * window * 1, tensor future = num of windows * 1.\n",
    "    '''\n",
    "    history = np.zeros((self.data_normalised.shape[0] - self.window - self.window_interval, self.window))\n",
    "    future = np.zeros((history.shape[0], 1))\n",
    "\n",
    "    for i in range(history.shape[0]):\n",
    "      for j in range(self.window):\n",
    "        history[i, j] = self.data_normalised[i + j]\n",
    "        future[i, 0] = self.data_normalised[self.window + i + self.window_interval]\n",
    "    \n",
    "    future = future.astype('float')\n",
    "    self.history_t = torch.from_numpy(history).unsqueeze(2)\n",
    "    self.future_t = torch.from_numpy(future)\n",
    "\n",
    "  def update(self, new_value: list[float]):\n",
    "    '''\n",
    "    Append the new values into the data and remove the same amount of data from the beginning.\n",
    "    The original self.data will be replaced, and then the data is normalised and scanned again.\n",
    "    \n",
    "    newvaue: A list of new_values to add into the original data.\n",
    "    '''\n",
    "    self.data = np.append(self.data, np.array(new_value))\n",
    "    self.data = self.data[len(new_value): ]\n",
    "\n",
    "    self._normalise()\n",
    "    self._scan()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20433e1c",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1630fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_data(dataclass: Read_data):\n",
    "#     '''\n",
    "#     This function is used to verify if the Read_data is implemented correctly.\n",
    "#     '''\n",
    "#     # Inspect the shape of data and compare the data_all, train_data and true_data.\n",
    "#     data_padded = np.pad(dataclass.data, (0, len(dataclass.data_all)-len(dataclass.data)), constant_values=np.nan)\n",
    "#     true_data_padded = np.pad(dataclass.true_data, (len(dataclass.data_all)-len(dataclass.true_data), 0), constant_values=np.nan)\n",
    "#     Plots.plot_lines(np.array([dataclass.data_all, data_padded, true_data_padded]).reshape(3, -1), size=(15, 6), \n",
    "#                      title='All Data', xlabel='Months', ylabel='Values', label=['data_all', 'train_data', 'true_data'], show_label=1, titlesize=18)\n",
    "\n",
    "#     # Check the values of the normalised data.\n",
    "#     Plots.plot_lines(np.array(dataclass.data_normalised).reshape(1, -1), size=(15, 6),\n",
    "#                      title='Normalised Data', xlabel='Months', ylabel='Values', label=['data_normalised'], show_label=1, titlesize=18)\n",
    "    \n",
    "#     # Check whether history windows are generated correctly.\n",
    "#     history = []\n",
    "#     for i in range(dataclass.history_t.shape[0]):\n",
    "#         history.append(dataclass.history_t[i, 0, 0].item())\n",
    "#     for i in range(1, dataclass.history_t.shape[1]):\n",
    "#         history.append(dataclass.history_t[-1, i, 0].item())\n",
    "#     print('History Tensors Check ' + str(np.array_equal(history, dataclass.data_normalised[ : -dataclass.window_interval-1, 0])))\n",
    "\n",
    "#     # # Check whether futures are generated correctly.\n",
    "#     future = []\n",
    "#     for i in range(dataclass.future_t.shape[0]):\n",
    "#         future.append(dataclass.future_t[i, 0].item())\n",
    "#     print('Future Tensors Check ' + str(np.array_equal(future, dataclass.data_normalised[dataclass.window+dataclass.window_interval : , 0])))\n",
    "\n",
    "#     # Validation the updation function.\n",
    "#     if dataclass.name == 'Demand':\n",
    "#         previous = dataclass.data_normalised\n",
    "#         dataclass.update([3000, 2900, 2800, 3100])\n",
    "#         Plots.plot_lines(np.array([previous, dataclass.data_normalised]).reshape(2, -1), size=(15, 6), \n",
    "#                         title='Update Comparison', xlabel='Months', ylabel='Values', label=['previous data', 'updated data'], show_label=1, titlesize=18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7094e63c",
   "metadata": {},
   "source": [
    "## Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250f0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUL_DEMAND = 1500\n",
    "# MUL_PRICE = 1000/340.2\n",
    "# MUL_YIELD = 2000\n",
    "\n",
    "# TRUE_WEEKS = 12\n",
    "\n",
    "# demand = Read_data('../Strawberry Demand.csv', 'Demand', true_weeks=TRUE_WEEKS, mul=MUL_DEMAND)\n",
    "# price = Read_data('../Strawberry Price.csv', 'Price', true_weeks=TRUE_WEEKS, mul=MUL_PRICE)\n",
    "# syield = Read_data('../Yield.csv', 'Yield', true_weeks=TRUE_WEEKS, mul=MUL_YIELD)\n",
    "# check_data(demand)\n",
    "# check_data(price)\n",
    "# check_data(syield)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
